version: '3.1'

services:

  # db:
  #   image: postgres
  #   restart: always
  #   environment:
  #     POSTGRES_USER: postgres
  #     POSTGRES_PASSWORD: postgres
  #     POSTGRES_DB: ostock_dev
  #   ports:
  #     - 5432:5432

  # keycloak:
  #   image: jboss/keycloak
  #   restart: always
  #   environment:
  #     KEYCLOAK_USER: admin
  #     KEYCLOAK_PASSWORD: admin
  #   ports:
  #     - "8080:8080"
  #   networks:
  #     backend:
  #       aliases:
  #         - "keycloak"

  
  # zookeeper:
  #   image: confluentinc/cp-zookeeper:7.3.0
  #   container_name: zookeeper
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000

  # broker:
  #   image: confluentinc/cp-kafka:7.3.0
  #   container_name: broker
  #   ports:
  #     - "9092:9092"
  #   depends_on:
  #     - zookeeper
  #   environment:
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  #     KAFKA_CREATE_TOPICS: orgChangeTopic:1:1

  # zookeeper:
  #   image: confluentinc/cp-zookeeper:7.3.0
  #   container_name: zookeeper
  #   ports:
  #     - 2181:2181
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   networks:
  #     backend:
  #       aliases:
  #         - "zookeeper"

  # kafka:
  #   image: confluentinc/cp-kafka:7.3.0
  #   container_name: broker
  #   ports:
  #     - 9092:9092
  #   environment:
  #     KAFKA_ADVERTISED_HOST_NAME: kafka
  #     KAFKA_ADVERTISED_PORT: 9092
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_CREATE_TOPICS: dresses:1:1,ratings:1:1
    # volumes:
    #   - "/var/run/docker.sock:/var/run/docker.sock"
    # depends_on:
    #   - zookeeper
    # networks:
    #   backend:
    #     aliases:
    #       - "kafka"

  # redisserver:
  #   image: redis:alpine
  #   ports:
  #     - 6379:6379
  #   networks:
  #     backend:
  #       aliases:
  #         - "redis"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: elasticsearch
    volumes:
      - elasticdata:/usr/share/elasticsearch/data
    ports:
      - 9300:9300
      - 9200:9200
    environment:
    # Define que será executado em apenas um nó
      discovery.type: "single-node" 
      # Define o tamanho mínimo e máximo do heap
      ES_JAVA_OPTS: "-Xms2g -Xmx2g"
      # Habilita para monitorar o comportamento do elastic
      xpack.monitoring.enabled: "true"

  # kibana:
  #   image: docker.elastic.co/kibana/kibana:7.7.0
  #   container_name: kibana
  #   environment:
  #     ELASTICSEARCH_URL: "http://elasticsearch:9300"
  #   ports:
  #     - 5601:5601
  
  # logstash:
  #   image: docker.elastic.co/logstash/logstash:7.7.0
  #   container_name: logstash
  #   command: logstash -f /etc/logstash/conf.d/logstash.conf
  #   volumes:
  #     - ./config:/etc/logstash/conf.d
  #   ports:
  #     - "5000:5000"
  #   networks:
  #     backend:
  #       aliases:
  #         - "logstash"
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 50M
  #       reservations:
  #         memory: 20M

  zipkin:
    image: openzipkin/zipkin
    container_name: zipkin
    # depends_on: 
    #   - elasticsearch
    # environment:
    #   - STORAGE_TYPE=elasticsearch
    #   - "ES_HOSTS=elasticsearch:9300"
    ports:
      - 9411:9411
    networks:
      backend:
        aliases:
          - "zipkin"
volumes:
  elasticdata:
    driver: local
networks:
  backend:
    driver: bridge